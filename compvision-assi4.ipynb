{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom skimage.transform import resize\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping ,ReduceLROnPlateau\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout \nimport os\nfrom keras.applications.vgg16 import preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T15:09:37.291612Z","iopub.execute_input":"2022-02-01T15:09:37.292121Z","iopub.status.idle":"2022-02-01T15:09:43.149864Z","shell.execute_reply.started":"2022-02-01T15:09:37.29204Z","shell.execute_reply":"2022-02-01T15:09:43.149115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Assigning the data Paths for the test, train , and Val sets.**","metadata":{}},{"cell_type":"code","source":"train_images_path = \"../input/assi4-dataset/resized_training/resized_training\" \ntrain_mask_path = \"../input/assi4-dataset/resized_training_mask/resized_training_mask\"\ntrain_metadata_path = \"../input/assi4-dataset/ISIC-2017_Training_Data_metadata.csv\"\n\nval_images_path = \"../input/assi4-dataset/resized_val/resized_val\"\nval_mask_path = \"../input/assi4-dataset/resized_val_mask/resized_val_mask\"\nval_metadata_path = \"../input/assi4-dataset/ISIC-2017_Validation_Data_metadata.csv\"\n\ntest_images_path = \"../input/assi4-dataset/resized_test/resized_test\"\ntest_mask_path = \"../input/assi4-dataset/resized_test_mask/resized_test_mask\"\ntest_metadata_path = \"../input/assi4-dataset/ISIC-2017_Test_v2_Data_metadata.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:09:43.15141Z","iopub.execute_input":"2022-02-01T15:09:43.15169Z","iopub.status.idle":"2022-02-01T15:09:43.159735Z","shell.execute_reply.started":"2022-02-01T15:09:43.151651Z","shell.execute_reply":"2022-02-01T15:09:43.159038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Auxillary Function for Reading the Meta Data**","metadata":{}},{"cell_type":"code","source":"def read_metadata(path):\n    metadata_Dataframe = pd.read_csv(path)\n    metadata_Dataframe.head()\n    return metadata_Dataframe","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:09:43.161913Z","iopub.execute_input":"2022-02-01T15:09:43.162596Z","iopub.status.idle":"2022-02-01T15:09:43.168242Z","shell.execute_reply.started":"2022-02-01T15:09:43.162557Z","shell.execute_reply":"2022-02-01T15:09:43.167614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading and Preparing the Images**","metadata":{}},{"cell_type":"code","source":"def load_images_from_folder(path,ids):\n    images = []\n    for imageId in ids:\n        images.append( cv2.resize(cv2.imread(os.path.join(path,imageId+'.jpg')), (256,256), interpolation = cv2.INTER_AREA) )\n    print('images load done')\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:09:43.170351Z","iopub.execute_input":"2022-02-01T15:09:43.170658Z","iopub.status.idle":"2022-02-01T15:09:43.177238Z","shell.execute_reply.started":"2022-02-01T15:09:43.170586Z","shell.execute_reply":"2022-02-01T15:09:43.17627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading and Preparing the Mask Images**","metadata":{}},{"cell_type":"code","source":"def load_masks_from_folder(path,ids):\n    images = []\n    for imageId in ids:\n        img = cv2.imread(os.path.join(path,imageId+'.png'))\n        img = tf.image.resize(img, (256,256), method='nearest')\n        img = tf.image.rgb_to_grayscale(img)/255\n        images.append(img)\n    print('images load done')\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:09:43.178307Z","iopub.execute_input":"2022-02-01T15:09:43.178703Z","iopub.status.idle":"2022-02-01T15:09:43.185157Z","shell.execute_reply.started":"2022-02-01T15:09:43.178665Z","shell.execute_reply":"2022-02-01T15:09:43.184473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_metadata = read_metadata(train_metadata_path)\nval_metadata = read_metadata(val_metadata_path)\ntest_metadata = read_metadata(test_metadata_path)\ntrain_images_ids = train_metadata['image_id']\nval_images_ids = val_metadata['image_id']\ntest_images_ids = test_metadata['image_id']\n\n\ntrain_images = load_images_from_folder(train_images_path,train_images_ids)\nval_images = load_images_from_folder(val_images_path,val_images_ids)\n\ntest_images = load_images_from_folder(test_images_path,test_images_ids)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:09:43.186506Z","iopub.execute_input":"2022-02-01T15:09:43.186996Z","iopub.status.idle":"2022-02-01T15:10:18.167771Z","shell.execute_reply.started":"2022-02-01T15:09:43.186954Z","shell.execute_reply":"2022-02-01T15:10:18.166958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_masks = load_masks_from_folder(train_mask_path,train_images_ids)\nval_masks = load_masks_from_folder(val_mask_path,val_images_ids)\n\ntest_masks = load_masks_from_folder(test_mask_path,test_images_ids)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:10:18.169104Z","iopub.execute_input":"2022-02-01T15:10:18.169611Z","iopub.status.idle":"2022-02-01T15:10:58.130033Z","shell.execute_reply.started":"2022-02-01T15:10:18.169555Z","shell.execute_reply":"2022-02-01T15:10:58.129231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking the reading process and presenting Sample Images**","metadata":{}},{"cell_type":"code","source":"plt.figure()\nplt.title( \"Train img \")\nplt.imshow(train_images[0])\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(train_masks[0])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(val_images[0])\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(val_masks[0])\n\nplt.figure()\nplt.title( \"Test img\")\nplt.imshow(test_images[0])\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(test_masks[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:10:58.138517Z","iopub.execute_input":"2022-02-01T15:10:58.139086Z","iopub.status.idle":"2022-02-01T15:10:59.349522Z","shell.execute_reply.started":"2022-02-01T15:10:58.139021Z","shell.execute_reply":"2022-02-01T15:10:59.348767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:10:59.350789Z","iopub.execute_input":"2022-02-01T15:10:59.35121Z","iopub.status.idle":"2022-02-01T15:10:59.357478Z","shell.execute_reply.started":"2022-02-01T15:10:59.351173Z","shell.execute_reply":"2022-02-01T15:10:59.356532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The CallBack Functions Used during the Training Process**","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(patience=7, verbose=1), #verbose -> update msg\n    ModelCheckpoint('model-v1.h5', verbose=0, save_best_only=True)\n]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:10:59.360832Z","iopub.execute_input":"2022-02-01T15:10:59.361422Z","iopub.status.idle":"2022-02-01T15:10:59.366902Z","shell.execute_reply.started":"2022-02-01T15:10:59.361381Z","shell.execute_reply":"2022-02-01T15:10:59.366034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The Jaccard IoU Loss Function used in our Training Process**","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\ndef jacard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef jacard_coef_loss(y_true, y_pred):\n    return -jacard_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:10:59.382901Z","iopub.execute_input":"2022-02-01T15:10:59.383222Z","iopub.status.idle":"2022-02-01T15:10:59.39Z","shell.execute_reply.started":"2022-02-01T15:10:59.38318Z","shell.execute_reply":"2022-02-01T15:10:59.389228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FCN-base-VGG16","metadata":{}},{"cell_type":"code","source":"inputImg = tf.keras.layers.Input((256,256,3) , name='image')  #shape of each img = 256*256*3\n#inputImg = Lambda(lambda x: x / 255)(inputImg)  #normalizing the input\nc1 = tf.keras.layers.Conv2D(64, (3, 3),  activation='relu' , padding=\"same\") (inputImg)\nc1 = tf.keras.layers.Conv2D(64, (3, 3),  activation='relu' , padding=\"same\") (c1)\np1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c1)\n#-------------------------------------------------------------------------------------\nc2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu' , padding=\"same\") (p1)\nc2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu' , padding=\"same\") (c2)\np2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c2)\n#-------------------------------------------------------------------------------------\nc3 = tf.keras.layers.Conv2D(256, (3, 3),  activation='relu' , padding=\"same\") (p2)\nc3 = tf.keras.layers.Conv2D(256, (3, 3),  activation='relu' , padding=\"same\") (c3)\nc3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu' , padding=\"same\") (c3)\np3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c3)\n#-------------------------------------------------------------------------------------\nc4 = tf.keras.layers.Conv2D(512, (3, 3),  activation='relu' , padding=\"same\") (p3)\nc4 = tf.keras.layers.Conv2D(512, (3, 3),  activation='relu' , padding=\"same\") (c4)\nc4 = tf.keras.layers.Conv2D(512, (3, 3),  activation='relu' , padding=\"same\") (c4)\np4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n#-------------------------------------------------------------------------------------\nc5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu' , padding=\"same\") (p4)\nc5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu' , padding=\"same\") (c5)\nc5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu' , padding=\"same\") (c5)\np5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2)) (c5)\n#-------------------------------------------------------------------------------------\n\nAdded_c6 = tf.keras.layers.Conv2D(4096, (1, 1),  kernel_initializer='he_uniform',activation='relu' , padding=\"same\") (p5)\nAdded_c6 = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer='he_uniform', activation='relu' , padding=\"same\") (Added_c6)\noutput = tf.keras.layers.Conv2DTranspose(1, (7, 7), strides=(32, 32), activation='sigmoid', padding=\"same\") (Added_c6)\n\n\nFCN_base_model_lr_1 = tf.keras.Model(inputs=[inputImg], outputs=[output])\nFCN_base_model_lr_01 = tf.keras.Model(inputs=[inputImg], outputs=[output])\nFCN_base_model_lr_001 = tf.keras.Model(inputs=[inputImg], outputs=[output])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OverFitting a Small Batch of Data**","metadata":{}},{"cell_type":"code","source":"small_train_images = train_images [:100]\nsmall_train_masks = train_masks [:100]\nsmall_val_images = val_images [:20]\nsmall_val_masks = val_masks [:20]\n\n\nFCN_base_model_lr_1.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nFCN_base_model_lr_1.summary()\n\n\n\n\n\n\nFCN_base_model_overfitting_results = FCN_base_model_lr_1.fit({'image': small_train_images}, small_train_masks, batch_size=5, epochs=50,callbacks=callbacks,\n                             validation_data=({ 'image' : small_val_images}, small_val_masks))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_base_model_overfitting_results.history['loss']\n#val_loss = FCN_base_model_overfitting_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\n#plt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FCN Model  with Learning rate = 0.1**","metadata":{}},{"cell_type":"code","source":"'''\nmodel.load_weights('model-v1.h5')\nFCN_base_model_results = model.fit({'image': train_images}, train_masks, batch_size=32, epochs=30,callbacks=callbacks,\n                             validation_data=({ 'image' : val_images}, val_masks))\n                             \n'''                             ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate= 0.1\nFCN_base_model_lr_1.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nFCN_base_model_lr_1.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_1.load_weights('model-v1.h5')\n\nFCN_base_model_lr_1_results = FCN_base_model_lr_1.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_base_model_lr_1_results.history['loss']\nval_loss = FCN_base_model_lr_1_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_1_score = FCN_base_model_lr_1.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {FCN_base_model_lr_1_score[0]} / Test accuracy: {FCN_base_model_lr_1_score[1]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nFCN_base_model_lr_1_pred = FCN_base_model_lr_1.predict(val_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(FCN_base_model_lr_1_pred[30])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(val_images[30])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(val_masks[30])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FCN Model  with Learning rate = 0.01**","metadata":{}},{"cell_type":"code","source":"# Learning Rate= 0.01\nFCN_base_model_lr_01.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nFCN_base_model_lr_01.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_01_results = FCN_base_model_lr_01.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_base_model_lr_01_results.history['loss']\nval_loss = FCN_base_model_lr_01_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_01_score = FCN_base_model_lr_01.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {FCN_base_model_lr_01_score[0]} / Test accuracy: {FCN_base_model_lr_01_score[1]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_01_pred = FCN_base_model_lr_01.predict(val_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(FCN_base_model_lr_1_pred[10])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(val_images[10])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(val_masks[10])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FCN Model  with Learning rate = 0.001**","metadata":{}},{"cell_type":"code","source":"# Learning Rate= 0.001\nFCN_base_model_lr_001.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\n\nFCN_base_model_lr_001.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_001_results = FCN_base_model_lr_001.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_base_model_lr_001_results.history['loss']\nval_loss = FCN_base_model_lr_001_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_base_model_lr_001_score = FCN_base_model_lr_001.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {FCN_base_model_lr_001_score[0]} / Test accuracy: {FCN_base_model_lr_001_score[1]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predicting the Results**","metadata":{}},{"cell_type":"code","source":"x=FCN_base_model.predict(np.expand_dims(small_train_images[15],axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.imshow(x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Pretrained FCN-VGG16**","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG16(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=(256, 256, 3),\n    include_top=False)  # Do not include the ImageNet classifier at the top.\nbase_model.trainable = False\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:12:51.979747Z","iopub.execute_input":"2022-02-01T15:12:51.980452Z","iopub.status.idle":"2022-02-01T15:12:53.21405Z","shell.execute_reply.started":"2022-02-01T15:12:51.980413Z","shell.execute_reply":"2022-02-01T15:12:53.213194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputImg = tf.keras.layers.Input((256,256,3) , name='image')\n#s = Lambda(lambda x: x / 255)(inputImg)   \nx = base_model(inputImg,training=False)\n#tf.keras.layers.Flatten()(model.layers[-1].output)\nimageModelOutput = tf.keras.layers.GlobalAveragePooling2D()(x)\n#b1 = tf.keras.layers.BatchNormalization()(imageModelOutput)\n#d1 = tf.keras.layers.Dense(16, activation='relu' )(imageModelOutput)\n#d1 = tf.keras.layers.Dense(32, activation='relu' )(d1)\n#d1 = tf.keras.layers.Dense(64, activation='relu' )(d1)\n#d1 = tf.keras.layers.Dense(128, activation='relu' )(d1)\nd1 = tf.keras.layers.Dense(256, activation='relu' )(imageModelOutput)\n\nreshaped = tf.keras.layers.Reshape((16, 16,1), input_shape=(256,)) (d1)\n\nc1Dec = tf.keras.layers.Conv2DTranspose(16, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (reshaped)\nc1Dec = tf.keras.layers.Conv2DTranspose(32, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c1Dec)\nc1Dec = tf.keras.layers.Conv2DTranspose(64, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c1Dec)\nc1Dec = tf.keras.layers.Conv2DTranspose(2, (3, 3),strides=(2, 2), activation='relu', padding=\"same\") (c1Dec)\n#c4Dec = tf.keras.layers.UpSampling2D(size=(16, 16))(reshaped)\nfinalOutput = tf.keras.layers.Conv2D(1, (1, 1),activation='sigmoid') (c1Dec)\n\n\n\nFCN_Pretrained_lr_1 = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\nFCN_Pretrained_lr_01 = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\nFCN_Pretrained_lr_001 = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:12:54.99381Z","iopub.execute_input":"2022-02-01T15:12:54.994352Z","iopub.status.idle":"2022-02-01T15:12:55.130606Z","shell.execute_reply.started":"2022-02-01T15:12:54.994314Z","shell.execute_reply":"2022-02-01T15:12:55.12993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PreTrained-FCN Model  with Learning rate = 0.1**","metadata":{}},{"cell_type":"code","source":"FCN_Pretrained_lr_1.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nFCN_Pretrained_lr_1.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:13:02.048297Z","iopub.execute_input":"2022-02-01T15:13:02.049134Z","iopub.status.idle":"2022-02-01T15:13:02.076761Z","shell.execute_reply.started":"2022-02-01T15:13:02.049095Z","shell.execute_reply":"2022-02-01T15:13:02.075931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_1_results = FCN_Pretrained_lr_1.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:13:04.608401Z","iopub.execute_input":"2022-02-01T15:13:04.608659Z","iopub.status.idle":"2022-02-01T15:19:29.464021Z","shell.execute_reply.started":"2022-02-01T15:13:04.60863Z","shell.execute_reply":"2022-02-01T15:19:29.46314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_Pretrained_lr_1_results.history['loss']\nval_loss = FCN_Pretrained_lr_1_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:19:29.466044Z","iopub.execute_input":"2022-02-01T15:19:29.466301Z","iopub.status.idle":"2022-02-01T15:19:29.670901Z","shell.execute_reply.started":"2022-02-01T15:19:29.466265Z","shell.execute_reply":"2022-02-01T15:19:29.670212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_1_score = FCN_Pretrained_lr_1.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {FCN_Pretrained_lr_1_score[0]} / Test accuracy: {FCN_Pretrained_lr_1_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:19:29.672502Z","iopub.execute_input":"2022-02-01T15:19:29.673064Z","iopub.status.idle":"2022-02-01T15:19:40.797915Z","shell.execute_reply.started":"2022-02-01T15:19:29.673024Z","shell.execute_reply":"2022-02-01T15:19:40.795863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_1_pred = FCN_Pretrained_lr_1.predict(val_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(FCN_Pretrained_lr_1_pred[10])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(val_images[10])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(val_masks[10])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:19:40.800292Z","iopub.execute_input":"2022-02-01T15:19:40.805044Z","iopub.status.idle":"2022-02-01T15:19:42.139298Z","shell.execute_reply.started":"2022-02-01T15:19:40.805004Z","shell.execute_reply":"2022-02-01T15:19:42.138426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PreTrained-FCN Model  with Learning rate = 0.01**","metadata":{}},{"cell_type":"code","source":"FCN_Pretrained_lr_01.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nFCN_Pretrained_lr_01.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:10.973037Z","iopub.execute_input":"2022-02-01T15:26:10.976948Z","iopub.status.idle":"2022-02-01T15:26:11.014619Z","shell.execute_reply.started":"2022-02-01T15:26:10.976906Z","shell.execute_reply":"2022-02-01T15:26:11.013978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_01_results = FCN_Pretrained_lr_01.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:11.017207Z","iopub.execute_input":"2022-02-01T15:26:11.018009Z","iopub.status.idle":"2022-02-01T15:32:35.650599Z","shell.execute_reply.started":"2022-02-01T15:26:11.017971Z","shell.execute_reply":"2022-02-01T15:32:35.649629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_Pretrained_lr_01_results.history['loss']\nval_loss = FCN_Pretrained_lr_01_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:32:35.652241Z","iopub.execute_input":"2022-02-01T15:32:35.652492Z","iopub.status.idle":"2022-02-01T15:32:35.928029Z","shell.execute_reply.started":"2022-02-01T15:32:35.652457Z","shell.execute_reply":"2022-02-01T15:32:35.927392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_01_score = FCN_Pretrained_lr_01.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {FCN_Pretrained_lr_01_score[0]} / Test accuracy: {FCN_Pretrained_lr_01_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:32:35.933856Z","iopub.execute_input":"2022-02-01T15:32:35.93487Z","iopub.status.idle":"2022-02-01T15:32:38.56592Z","shell.execute_reply.started":"2022-02-01T15:32:35.934824Z","shell.execute_reply":"2022-02-01T15:32:38.565086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_01_pred = FCN_Pretrained_lr_01.predict(val_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(FCN_Pretrained_lr_01_pred[10])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(val_images[10])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(val_masks[10])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:32:38.56716Z","iopub.execute_input":"2022-02-01T15:32:38.573529Z","iopub.status.idle":"2022-02-01T15:32:40.330126Z","shell.execute_reply.started":"2022-02-01T15:32:38.573487Z","shell.execute_reply":"2022-02-01T15:32:40.329284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PreTrained-FCN Model  with Learning rate = 0.001**","metadata":{}},{"cell_type":"code","source":"FCN_Pretrained_lr_001.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nFCN_Pretrained_lr_001.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:19:42.140706Z","iopub.execute_input":"2022-02-01T15:19:42.141036Z","iopub.status.idle":"2022-02-01T15:19:42.166056Z","shell.execute_reply.started":"2022-02-01T15:19:42.140997Z","shell.execute_reply":"2022-02-01T15:19:42.165245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_001_results = FCN_Pretrained_lr_001.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:19:42.167347Z","iopub.execute_input":"2022-02-01T15:19:42.168296Z","iopub.status.idle":"2022-02-01T15:26:06.613571Z","shell.execute_reply.started":"2022-02-01T15:19:42.168227Z","shell.execute_reply":"2022-02-01T15:26:06.612744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = FCN_Pretrained_lr_001_results.history['loss']\nval_loss = FCN_Pretrained_lr_001_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:06.614985Z","iopub.execute_input":"2022-02-01T15:26:06.615336Z","iopub.status.idle":"2022-02-01T15:26:06.816864Z","shell.execute_reply.started":"2022-02-01T15:26:06.615297Z","shell.execute_reply":"2022-02-01T15:26:06.816198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_001_score = FCN_Pretrained_lr_001.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {FCN_Pretrained_lr_001_score[0]} / Test accuracy: {FCN_Pretrained_lr_001_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:06.818314Z","iopub.execute_input":"2022-02-01T15:26:06.818859Z","iopub.status.idle":"2022-02-01T15:26:09.379644Z","shell.execute_reply.started":"2022-02-01T15:26:06.818818Z","shell.execute_reply":"2022-02-01T15:26:09.375874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FCN_Pretrained_lr_001_pred = FCN_Pretrained_lr_001.predict(val_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(FCN_Pretrained_lr_001_pred[10])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(val_images[10])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(val_masks[10])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:26:09.380807Z","iopub.execute_input":"2022-02-01T15:26:09.381258Z","iopub.status.idle":"2022-02-01T15:26:10.968976Z","shell.execute_reply.started":"2022-02-01T15:26:09.381212Z","shell.execute_reply":"2022-02-01T15:26:10.968329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-NET","metadata":{}},{"cell_type":"code","source":"inputImg = tf.keras.layers.Input((256,256,3) , name='image')\ns = Lambda(lambda x: x / 255)(inputImg)   \nc1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n#c1 = Dropout(0.1)(c1)\nc1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\np1 = MaxPooling2D((2, 2))(c1)\n\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n#c2 = Dropout(0.1)(c2)\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\np2 = MaxPooling2D((2, 2))(c2)\n\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n#c3 = Dropout(0.2)(c3)\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\np3 = MaxPooling2D((2, 2))(c3)\n\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n#c4 = Dropout(0.2)(c4)\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\np4 = MaxPooling2D(pool_size=(2, 2))(c4)\n\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n#c5 = Dropout(0.3)(c5)\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n#Expansive path \nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n#c6 = Dropout(0.2)(c6)\nc6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n#c7 = Dropout(0.2)(c7)\nc7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n#c8 = Dropout(0.1)(c8)\nc8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n#c9 = Dropout(0.1)(c9)\nc9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n\nfinalOutput = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n\n\n\n\nUNET_lr_1 = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\nUNET_lr_01 = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])\nUNET_lr_001 = tf.keras.Model(inputs=[inputImg], outputs=[finalOutput])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:45:19.741784Z","iopub.execute_input":"2022-01-31T19:45:19.742225Z","iopub.status.idle":"2022-01-31T19:45:20.288112Z","shell.execute_reply.started":"2022-01-31T19:45:19.74218Z","shell.execute_reply":"2022-01-31T19:45:20.287394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss=[jacard_coef_loss],\n    metrics=[[jacard_coef],'accuracy'])\n#model.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])\n\nmodel.summary()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**U-Net Model  with Learning rate = 0.1**","metadata":{}},{"cell_type":"raw","source":"UNET_lr_1.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nUNET_lr_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T17:54:03.105825Z","iopub.execute_input":"2022-01-31T17:54:03.106251Z","iopub.status.idle":"2022-01-31T17:54:03.146109Z","shell.execute_reply.started":"2022-01-31T17:54:03.106208Z","shell.execute_reply":"2022-01-31T17:54:03.145507Z"}}},{"cell_type":"code","source":"UNET_lr_1.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss=[jacard_coef_loss],\n    metrics=[[jacard_coef],'accuracy'])\n#model.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])\n\nUNET_lr_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:45:27.473965Z","iopub.execute_input":"2022-01-31T19:45:27.474621Z","iopub.status.idle":"2022-01-31T19:45:27.505731Z","shell.execute_reply.started":"2022-01-31T19:45:27.474581Z","shell.execute_reply":"2022-01-31T19:45:27.505087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_1_results = UNET_lr_1.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:45:36.328509Z","iopub.execute_input":"2022-01-31T19:45:36.328944Z","iopub.status.idle":"2022-01-31T19:54:22.56489Z","shell.execute_reply.started":"2022-01-31T19:45:36.328907Z","shell.execute_reply":"2022-01-31T19:54:22.564162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = UNET_lr_1_results.history['loss']\nval_loss = UNET_lr_1_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:54:22.566937Z","iopub.execute_input":"2022-01-31T19:54:22.56719Z","iopub.status.idle":"2022-01-31T19:54:22.760378Z","shell.execute_reply.started":"2022-01-31T19:54:22.567155Z","shell.execute_reply":"2022-01-31T19:54:22.759703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_1_score = UNET_lr_1.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {UNET_lr_1_score[0]} / Test accuracy: {UNET_lr_1_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:54:22.761729Z","iopub.execute_input":"2022-01-31T19:54:22.761999Z","iopub.status.idle":"2022-01-31T19:54:26.598172Z","shell.execute_reply.started":"2022-01-31T19:54:22.761962Z","shell.execute_reply":"2022-01-31T19:54:26.59744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_1_pred = UNET_lr_1.predict(test_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(UNET_lr_1_pred[50])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(test_images[50])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(test_masks[50])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:17:02.279908Z","iopub.execute_input":"2022-01-31T20:17:02.280176Z","iopub.status.idle":"2022-01-31T20:17:04.346122Z","shell.execute_reply.started":"2022-01-31T20:17:02.280146Z","shell.execute_reply":"2022-01-31T20:17:04.345389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**U-Net Model  with Learning rate = 0.01**","metadata":{}},{"cell_type":"raw","source":"UNET_lr_01.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nUNET_lr_01.summary()","metadata":{}},{"cell_type":"code","source":"UNET_lr_01.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss=[jacard_coef_loss],\n    metrics=[[jacard_coef],'accuracy'])\n#model.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])\n\nUNET_lr_01.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:54:28.528651Z","iopub.execute_input":"2022-01-31T19:54:28.528925Z","iopub.status.idle":"2022-01-31T19:54:28.558464Z","shell.execute_reply.started":"2022-01-31T19:54:28.528889Z","shell.execute_reply":"2022-01-31T19:54:28.557831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_01_results = UNET_lr_01.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:54:28.559644Z","iopub.execute_input":"2022-01-31T19:54:28.561995Z","iopub.status.idle":"2022-01-31T19:57:46.118322Z","shell.execute_reply.started":"2022-01-31T19:54:28.561956Z","shell.execute_reply":"2022-01-31T19:57:46.117601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = UNET_lr_01_results.history['loss']\nval_loss = UNET_lr_01_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:57:46.120727Z","iopub.execute_input":"2022-01-31T19:57:46.121379Z","iopub.status.idle":"2022-01-31T19:57:54.116324Z","shell.execute_reply.started":"2022-01-31T19:57:46.121334Z","shell.execute_reply":"2022-01-31T19:57:54.115663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_01_score = UNET_lr_01.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {UNET_lr_01_score[0]} / Test accuracy: {UNET_lr_01_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:57:54.11779Z","iopub.execute_input":"2022-01-31T19:57:54.118292Z","iopub.status.idle":"2022-01-31T19:57:55.751279Z","shell.execute_reply.started":"2022-01-31T19:57:54.118251Z","shell.execute_reply":"2022-01-31T19:57:55.750507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_01_pred = UNET_lr_01.predict(test_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(UNET_lr_1_pred[50])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(test_images[50])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(test_masks[50])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:17:19.537332Z","iopub.execute_input":"2022-01-31T20:17:19.537812Z","iopub.status.idle":"2022-01-31T20:17:21.588161Z","shell.execute_reply.started":"2022-01-31T20:17:19.537774Z","shell.execute_reply":"2022-01-31T20:17:21.587371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**U-Net Model  with Learning rate = 0.001**","metadata":{}},{"cell_type":"raw","source":"UNET_lr_001.compile(optimizer= tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n    loss=[jacard_coef_loss],\n    metrics=['accuracy',jacard_coef,tf.keras.metrics.MeanIoU(num_classes=2)])\n\nUNET_lr_001.summary()","metadata":{}},{"cell_type":"code","source":"UNET_lr_001.compile(optimizer=tf.keras.optimizers.RMSprop(\n    learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n    name='RMSprop'),\n    loss=[jacard_coef_loss],\n    metrics=[[jacard_coef],'accuracy'])\n#model.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])\n\nUNET_lr_001.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:57:57.996776Z","iopub.execute_input":"2022-01-31T19:57:57.997058Z","iopub.status.idle":"2022-01-31T19:57:58.02396Z","shell.execute_reply.started":"2022-01-31T19:57:57.997022Z","shell.execute_reply":"2022-01-31T19:57:58.02329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_001_results = UNET_lr_001.fit({'image': train_images}, train_masks, batch_size=64, epochs=50, callbacks=callbacks,\n                    validation_data=({ 'image' : val_images}, val_masks))","metadata":{"execution":{"iopub.status.busy":"2022-01-31T19:57:58.025083Z","iopub.execute_input":"2022-01-31T19:57:58.025391Z","iopub.status.idle":"2022-01-31T20:01:05.592362Z","shell.execute_reply.started":"2022-01-31T19:57:58.025354Z","shell.execute_reply":"2022-01-31T20:01:05.591669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = UNET_lr_001_results.history['loss']\nval_loss = UNET_lr_001_results.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:01:05.595071Z","iopub.execute_input":"2022-01-31T20:01:05.59555Z","iopub.status.idle":"2022-01-31T20:01:05.799325Z","shell.execute_reply.started":"2022-01-31T20:01:05.595518Z","shell.execute_reply":"2022-01-31T20:01:05.798667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_001_score = UNET_lr_001.evaluate(test_images, test_masks, verbose=0)\nprint(f'Test loss: {UNET_lr_001_score[0]} / Test accuracy: {UNET_lr_001_score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:01:05.800609Z","iopub.execute_input":"2022-01-31T20:01:05.800872Z","iopub.status.idle":"2022-01-31T20:01:07.427278Z","shell.execute_reply.started":"2022-01-31T20:01:05.800823Z","shell.execute_reply":"2022-01-31T20:01:07.426519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNET_lr_001_pred = UNET_lr_001.predict(test_images)\n\n\nplt.figure()\nplt.title( \"Predicted img\")\nplt.imshow(UNET_lr_1_pred[50])\n\nplt.figure()\nplt.title( \"Val img\")\nplt.imshow(test_images[50])\n\nplt.figure()\nplt.title( \"Ground truth\")\nplt.imshow(test_masks[50])","metadata":{"execution":{"iopub.status.busy":"2022-01-31T20:17:44.551155Z","iopub.execute_input":"2022-01-31T20:17:44.551421Z","iopub.status.idle":"2022-01-31T20:17:46.61571Z","shell.execute_reply.started":"2022-01-31T20:17:44.551393Z","shell.execute_reply":"2022-01-31T20:17:46.614905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"FCN_base_model_results = FCN_base_model.fit({'image': small_train_images}, small_train_masks, batch_size=5, epochs=50,callbacks=callbacks,\n                             validation_data=({ 'image' : small_val_images}, small_val_masks))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}